{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando funções externas utilizando LangChain\n",
    "\n",
    "LangChain é um framework para criação de aplicações de IA e naturalmente ele possui ferramentas para facilitar a criação de funções externas para serem passadas a api da OpenAI. Para a utilização do LangChain, será necessário entendermos brevemente uma outra biblioteca de Python chamada pydantic, uma bilioteca para validação de dados que facilita a construção de estruturas de dados mais robustas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzindo pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como criamos uma estrutura nova sem pydantic\n",
    "\n",
    "Sem utilizar pydantic, podemos criar uma estrutura de dados utilizando funções da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pessoa:\n",
    "    def __init__(self, nome: str, idade: int, peso: float) -> None:\n",
    "        self.nome = nome\n",
    "        self.idade = idade\n",
    "        self.peso = peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, criamos uma função que representa uma pessoa e tem os seguintes atributos: nome, idade e peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Pessoa at 0x2a090e03910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano = Pessoa('Adriano', 32, 68)\n",
    "adriano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano.idade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos setar os atributos com qualquer tipo de dado, pois o Python por padrão não faz checagem de tipos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Pessoa at 0x2a08f5b2250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano = Pessoa('Adriano', 32, 'ashdbadgvuya')\n",
    "adriano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ashdbadgvuya'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano.peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como criamos uma estrutura nova usando pydantic\n",
    "\n",
    "A sintaxe de pydantic acaba sendo bem mais simples para a criação de classes de dados, ao compararmos com a criação de classes comuns de Python. Nela, temos que cuidar com a definição do tipo de cada atributo, pois eles serão utilizados para validar se os dados fornecidos estão corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class pydPessoa(BaseModel):\n",
    "    nome: str\n",
    "    idade: int\n",
    "    peso: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydPessoa(nome='Adriano', idade=32, peso=68.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano = pydPessoa(nome='Adriano', idade=32, peso=68)\n",
    "adriano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adriano'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano.nome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O interessante é vermos que pydantic fornece uma validação automática de dados. Isso garante uma integridade muito maior em aplicações mais complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for pydPessoa\npeso\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='asuhdauishg', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.7/v/float_parsing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adriano \u001b[38;5;241m=\u001b[39m \u001b[43mpydPessoa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdriano\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masuhdauishg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avsoares\\OneDrive\\Documentos\\GitHub\\courses\\Agents LangChain\\scripts\\.venv\\Lib\\site-packages\\pydantic\\main.py:176\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    175\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for pydPessoa\npeso\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='asuhdauishg', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.7/v/float_parsing"
     ]
    }
   ],
   "source": [
    "adriano = pydPessoa(nome='Adriano', idade=32, peso='asuhdauishg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adriano = pydPessoa(nome='Adriano', idade=32, peso='68')\n",
    "adriano.peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer um nesting de classes de pydantic, onde uma classe de dados recebe como input outra classe de pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydAsimoTeam(funcionarios=[pydPessoa(nome='Adriano', idade=32, peso=68.0)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class pydAsimoTeam(BaseModel):\n",
    "    funcionarios: List[pydPessoa]\n",
    "\n",
    "pydAsimoTeam(funcionarios=[pydPessoa(nome='Adriano', idade=32, peso=68)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E a validação continua fucnionando mesmo com esta estrutura de nesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for pydAsimoTeam\nfuncionarios.0\n  Input should be a valid dictionary or instance of pydPessoa [type=model_type, input_value=<__main__.Pessoa object at 0x000002A0918F1250>, input_type=Pessoa]\n    For further information visit https://errors.pydantic.dev/2.7/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpydAsimoTeam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuncionarios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPessoa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdriano\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m68\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avsoares\\OneDrive\\Documentos\\GitHub\\courses\\Agents LangChain\\scripts\\.venv\\Lib\\site-packages\\pydantic\\main.py:176\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    175\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for pydAsimoTeam\nfuncionarios.0\n  Input should be a valid dictionary or instance of pydPessoa [type=model_type, input_value=<__main__.Pessoa object at 0x000002A0918F1250>, input_type=Pessoa]\n    For further information visit https://errors.pydantic.dev/2.7/v/model_type"
     ]
    }
   ],
   "source": [
    "pydAsimoTeam(funcionarios=[Pessoa(nome='Adriano', idade=32, peso=68)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando pydantic para criação de tools da OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def obter_temperatura_atual(local, unidade=\"celsius\"):\n",
    "    if \"são paulo\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"São Paulo\", \"temperatura\": \"32\", \"unidade\": unidade}\n",
    "            )\n",
    "    elif \"porto alegre\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"Porto Alegre\", \"temperatura\": \"25\", \"unidade\": unidade}\n",
    "            )\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"local\": local, \"temperatura\": \"unknown\"}\n",
    "            )\n",
    "    \n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"obter_temperatura_atual\",\n",
    "            \"description\": \"Obtém a temperatura atual em uma dada cidade\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"local\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"O nome da cidade. Ex: São Paulo\",\n",
    "                    },\n",
    "                    \"unidade\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"local\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class UnidadeEnum(str, Enum):\n",
    "    celsius = 'celsius'\n",
    "    fahrenheit = 'fahrenheit'\n",
    "\n",
    "class ObterTemperaturaAtual(BaseModel):\n",
    "    \"\"\"Obtém a temperatura atual de uma determinada localidade\"\"\"\n",
    "    local: str = Field(description='O nome da cidade', examples=['São Paulo', 'Porto Alegre'])\n",
    "    unidade: Optional[UnidadeEnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ObterTemperaturaAtual',\n",
       " 'description': 'Obtém a temperatura atual de uma determinada localidade',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'local': {'description': 'O nome da cidade',\n",
       "    'examples': ['São Paulo', 'Porto Alegre'],\n",
       "    'type': 'string'},\n",
       "   'unidade': {'description': 'An enumeration.',\n",
       "    'enum': ['celsius', 'fahrenheit'],\n",
       "    'type': 'string'}},\n",
       "  'required': ['local']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tool_temperatura = convert_to_openai_function(ObterTemperaturaAtual)\n",
    "tool_temperatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando função externa utilizando LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já sabemos criar funções que os modelos de llm entendam, podemos passar essas funções para os modelos de linguagem através da biblioteca langchain. Para isso temos duas formas, podemos utilizar o parâmetro functions ao chamar o método invoke dos chat_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 105, 'total_tokens': 128}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-3f10a6b4-3a36-4b74-b8fa-3a93f5d7a8c9-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "resposta = chat.invoke('Qual é a temperatura de Porto Alegre', functions=[tool_temperatura])\n",
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou podemos dar um bind e criar um novo componente de chat_model que terá acesso a função sempre que for chamado o invoke. Nestes dois casos, o modelo se comportará com o parâmetro \"auto\" de chamamento de função, ou seja, ele chamará a função quando necessitar, caso contrário se comportará como um modelo de linguagem normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 105, 'total_tokens': 128}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-c08b20b3-ec81-4302-8bcb-d28d71de2f41-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI()\n",
    "chat_com_func = chat.bind(functions=[tool_temperatura])\n",
    "resposta = chat_com_func.invoke('Qual é a temperatura de Porto Alegre')\n",
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obrigar o modelo a sempre chamar uma função da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 119, 'total_tokens': 128}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-19b720a6-e99c-4958-b03f-8eaef69d7452-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = chat.invoke(\n",
    "    'Qual é a temperatura de Porto Alegre', \n",
    "    functions=[tool_temperatura],\n",
    "    function_call={'name': 'ObterTemperaturaAtual'}\n",
    "    )\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"São Paulo\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 112, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2054b9dc-8063-48d8-81f1-a383a379f004-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = chat.invoke(\n",
    "    'Olá', \n",
    "    functions=[tool_temperatura],\n",
    "    function_call={'name': 'ObterTemperaturaAtual'}\n",
    "    )\n",
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando a uma chain\n",
    "\n",
    "Podemos adicionar agora este modelo com funções a um prompt e criar uma chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um assistente amigável chamado Isaac'),\n",
    "    ('user', '{input}')\n",
    "])\n",
    "\n",
    "chain = prompt | chat.bind(functions=[tool_temperatura])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá! Como posso ajudar você hoje?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 110, 'total_tokens': 122}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-52bab6ca-5c75-46e0-b340-67578d02fd45-0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Olá'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Florianopolis\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 115, 'total_tokens': 137}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-f2a120e6-23b4-4faf-8d10-96586d3d6a98-0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Qual a temperatura em Floripa?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
