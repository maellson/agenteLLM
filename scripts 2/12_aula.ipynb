{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools padrão do LangChain\n",
    "\n",
    "A biblioteca LangChain já possui diversas ferramentas padrão construídas que podemos utilizar. Elas podem ser verificadas neste link: https://python.langchain.com/v0.1/docs/integrations/tools/.\n",
    "Vamos mostrar como utilizar algumas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArXiv\n",
    "\n",
    "Esta ferramenta utiliza a biblioteca do arXiv para retornar resumos de artigos científicos de um determinado tema solicitado.\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/arxiv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos três formas em geral para chamar uma tool, da mais baixo a mais alto nível:\n",
    "- Criando a tool utilziando o Wrapper: no LangChain foram criados diferentes wrappers para apis e bibliotecas externas que facilitam a utilização das mesmas e permitem uma rápida criação de uma nova tool. Ela é mais customizável, pois podemos modificar as descrições e argumentos da tool às nossa necessidades, além de podermos modificar facilmente os parâmetros do wrapper\n",
    "- Instanciando a tool já criada: em geral, uma tool pronta já está criada dentro da biblioteca e podemos acessá-la diretamente\n",
    "- Utilizando o load_tools: o LangChain possui uma ferramnta especial chamada load_tools que permite o carregamento de diversas ferramentas ao mesmo tempo\n",
    "\n",
    "Vamos explorar os três métodos agora:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando tool manualmente através do Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "class ArxivArgs(BaseModel):\n",
    "    query:str = Field(description='Qyuery de busca no ArXiv')\n",
    "\n",
    "tool_arxiv = StructuredTool.from_function(\n",
    "    func=ArxivAPIWrapper(top_k_results=2).run,\n",
    "    args_schema=ArxivArgs,\n",
    "    name='arxiv',\n",
    "    description = (\n",
    "        \"Uma ferramenta em torno do Arxiv.org. \"\n",
    "        \"Útil para quando você precisa responder a perguntas sobre Física, Matemática, \"\n",
    "        \"Ciência da Computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, \"\n",
    "        \"Engenharia Elétrica e Economia utilizando artigos científicos do arxiv.org. \"\n",
    "        \"A entrada deve ser uma consulta de pesquisa em inglês.\"\n",
    "    ),\n",
    "    return_direct=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: arxiv(query: str) -> str - Uma ferramenta em torno do Arxiv.org. Útil para quando você precisa responder a perguntas sobre Física, Matemática, Ciência da Computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, Engenharia Elétrica e Economia utilizando artigos científicos do arxiv.org. A entrada deve ser uma consulta de pesquisa em inglês.\n",
      "Args: {'query': {'title': 'Query', 'description': 'Qyuery de busca no ArXiv', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print('Descrição:', tool_arxiv.description)\n",
    "print('Args:', tool_arxiv.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-01-08\\nTitle: A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends\\nAuthors: Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen Zhang, Dewu Zheng, Mingxi Ye, Jiachi Chen\\nSummary: General large language models (LLMs), represented by ChatGPT, have\\ndemonstrated significant potential in tasks such as code generation in software\\nengineering. This has led to the development of specialized LLMs for software\\nengineering, known as Code LLMs. A considerable portion of Code LLMs is derived\\nfrom general LLMs through model fine-tuning. As a result, Code LLMs are often\\nupdated frequently and their performance can be influenced by the base LLMs.\\nHowever, there is currently a lack of systematic investigation into Code LLMs\\nand their performance. In this study, we conduct a comprehensive survey and\\nanalysis of the types of Code LLMs and their differences in performance\\ncompared to general LLMs. We aim to address three questions: (1) What LLMs are\\nspecifically designed for software engineering tasks, and what is the\\nrelationship between these Code LLMs? (2) Do Code LLMs really outperform\\ngeneral LLMs in software engineering tasks? (3) Which LLMs are more proficient\\nin different software engineering tasks? To answer these questions, we first\\ncollect relevant literature and work from five major databases and open-source\\ncommunities, resulting in 134 works for analysis. Next, we categorize the Code\\nLLMs based on their publishers and examine their relationships with general\\nLLMs and among themselves. Furthermore, we investigate the performance\\ndifferences between general LLMs and Code LLMs in various software engineering\\ntasks to demonstrate the impact of base models and Code LLMs. Finally, we\\ncomprehensively maintained the performance of LLMs across multiple mainstream\\nbenchmarks to identify the best-performing LLMs for each software engineering\\ntask. Our research not only assists developers of Code LLMs in choosing base\\nmodels for the development of more advanced LLMs but also provides insights for\\npractitioners to better understand key improvement directions for Code LLMs.\\n\\nPublished: 2024-04-23\\nTitle: A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications\\nAuthors: Wenbo Shang, Xin Huang\\nSummary: A graph is a fundamental data model to represent various entities and their\\ncomplex relationships in society and nature, such as social networks,\\ntransportation networks, financial networks, and biomedical systems. Recently,\\nlarge language models (LLMs) have showcased a strong generalization ability to\\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\\nand specific-domain content generation. Compared with graph learning models,\\nLLMs enjoy superior advantages in addressing the challenges of generalizing\\ngraph tasks by eliminating the need for training graph learning models and\\nreducing the cost of manual annotation. In this survey, we conduct a\\ncomprehensive investigation of existing LLM studies on graph data, which\\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\\npoints out the existing remaining challenges and future directions.\\nSpecifically, we study the key problems of LLM-based generative graph analytics\\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\\napplications. LLM-GQP focuses on an integration of graph analytics techniques\\nand LLM prompts, including graph understanding and knowledge graph (KG) based\\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\\ngraphs, including graph learning, graph-formed reasoning and graph\\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\\nmodels. We also explore open problems a\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arxiv.run({'query': 'llm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando tool já criada no LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tool_arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n",
      "Args: {'query': {'title': 'Query', 'description': 'search query to look up', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print('Descrição:', tool_arxiv.description)\n",
    "print('Args:', tool_arxiv.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando tool através do load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivQueryRun()]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = load_tools(['arxiv'])\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArxivQueryRun()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arxiv = tools[0]\n",
    "tool_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n",
      "Args: {'query': {'title': 'Query', 'description': 'search query to look up', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print('Descrição:', tool_arxiv.description)\n",
    "print('Args:', tool_arxiv.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-01-08\\nTitle: A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends\\nAuthors: Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen Zhang, Dewu Zheng, Mingxi Ye, Jiachi Chen\\nSummary: General large language models (LLMs), represented by ChatGPT, have\\ndemonstrated significant potential in tasks such as code generation in software\\nengineering. This has led to the development of specialized LLMs for software\\nengineering, known as Code LLMs. A considerable portion of Code LLMs is derived\\nfrom general LLMs through model fine-tuning. As a result, Code LLMs are often\\nupdated frequently and their performance can be influenced by the base LLMs.\\nHowever, there is currently a lack of systematic investigation into Code LLMs\\nand their performance. In this study, we conduct a comprehensive survey and\\nanalysis of the types of Code LLMs and their differences in performance\\ncompared to general LLMs. We aim to address three questions: (1) What LLMs are\\nspecifically designed for software engineering tasks, and what is the\\nrelationship between these Code LLMs? (2) Do Code LLMs really outperform\\ngeneral LLMs in software engineering tasks? (3) Which LLMs are more proficient\\nin different software engineering tasks? To answer these questions, we first\\ncollect relevant literature and work from five major databases and open-source\\ncommunities, resulting in 134 works for analysis. Next, we categorize the Code\\nLLMs based on their publishers and examine their relationships with general\\nLLMs and among themselves. Furthermore, we investigate the performance\\ndifferences between general LLMs and Code LLMs in various software engineering\\ntasks to demonstrate the impact of base models and Code LLMs. Finally, we\\ncomprehensively maintained the performance of LLMs across multiple mainstream\\nbenchmarks to identify the best-performing LLMs for each software engineering\\ntask. Our research not only assists developers of Code LLMs in choosing base\\nmodels for the development of more advanced LLMs but also provides insights for\\npractitioners to better understand key improvement directions for Code LLMs.\\n\\nPublished: 2024-04-23\\nTitle: A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications\\nAuthors: Wenbo Shang, Xin Huang\\nSummary: A graph is a fundamental data model to represent various entities and their\\ncomplex relationships in society and nature, such as social networks,\\ntransportation networks, financial networks, and biomedical systems. Recently,\\nlarge language models (LLMs) have showcased a strong generalization ability to\\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\\nand specific-domain content generation. Compared with graph learning models,\\nLLMs enjoy superior advantages in addressing the challenges of generalizing\\ngraph tasks by eliminating the need for training graph learning models and\\nreducing the cost of manual annotation. In this survey, we conduct a\\ncomprehensive investigation of existing LLM studies on graph data, which\\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\\npoints out the existing remaining challenges and future directions.\\nSpecifically, we study the key problems of LLM-based generative graph analytics\\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\\napplications. LLM-GQP focuses on an integration of graph analytics techniques\\nand LLM prompts, including graph understanding and knowledge graph (KG) based\\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\\ngraphs, including graph learning, graph-formed reasoning and graph\\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\\nmodels. We also explore open problems a\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arxiv.run({'query': 'llm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python REPL\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "tool_repl = PythonREPLTool()\n",
    "print('Descrição:', tool_repl.description)\n",
    "print('Args:', tool_repl.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oi\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({'query': 'print(\"oi\")'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackOverflow\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/stackexchange/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A wrapper around StackExchange. Useful for when you need to answer specific programming questionscode excerpts, code examples and solutionsInput should be a fully formed question.\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(['stackexchange'])\n",
    "tool_stack = tools[0]\n",
    "print('Descrição:', tool_stack.description)\n",
    "print('Args:', tool_stack.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: While using groq for my project im getting this error\\ndef claim_agent(user_question):\\n    memory = ConversationBufferWindowMemory(ai_prefix=&quot;Insurance <span class=\"highlight\">Agent</span>&quot;, k=20)\\n    prompt_template = PromptTemplate(\\n        input_variables=[&#39;history&#39;, &#39;input&#39;], &hellip; &quot;D:\\\\Project_tests.venv\\\\Lib\\\\site-packages\\\\<span class=\"highlight\">langchain</span>\\\\chains\\\\base.py&quot;, line 163, in invoke\\nraise e\\nFile &quot;D:\\\\Project_tests.venv\\\\Lib\\\\site-packages\\\\<span class=\"highlight\">langchain</span>\\\\chains\\\\base.py&quot;, line 153, in invoke\\nself. &hellip; \\n\\nQuestion: NL2SQL Chatbot - Output Formatting Issue\\nI&#39;m utilizing the <span class=\"highlight\">Langchain</span> SQL <span class=\"highlight\">agent</span> for this purpose. However, the output I&#39;m receiving contains some formatting errors that I aim to rectify. &hellip; I tried using <span class=\"highlight\">Langchain</span> SQL <span class=\"highlight\">agent</span>. I need the output in proper format and in a proper sentence. For example -\\n\\nWhat is the Actor ID of role - Don Vito Corleone\\nAns. &hellip; \\n\\nQuestion: Web-searching tool for a langchain agent\\nI am building a RAG <span class=\"highlight\">agent</span> that is using a FAISS vector store to retrieve some information.\\nI also want to give this <span class=\"highlight\">agent</span> a tool to do web-searches. &hellip; I am looking for recommendations about other web-searching tools I can give to my <span class=\"highlight\">langchain</span> <span class=\"highlight\">agent</span>.\\nAre there any free of charge? &hellip; '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_stack.run({'query': 'LangChain Agents'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/filesystem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: copy_file\n",
      "Descrição: Create a copy of a file in a specified location\n",
      "Args: {'source_path': {'title': 'Source Path', 'description': 'Path of the file to copy', 'type': 'string'}, 'destination_path': {'title': 'Destination Path', 'description': 'Path to save the copied file', 'type': 'string'}}\n",
      "\n",
      "Name: file_delete\n",
      "Descrição: Delete a file\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'Path of the file to delete', 'type': 'string'}}\n",
      "\n",
      "Name: file_search\n",
      "Descrição: Recursively search for files in a subdirectory that match the regex pattern\n",
      "Args: {'dir_path': {'title': 'Dir Path', 'description': 'Subdirectory to search in.', 'default': '.', 'type': 'string'}, 'pattern': {'title': 'Pattern', 'description': 'Unix shell regex, where * matches everything.', 'type': 'string'}}\n",
      "\n",
      "Name: move_file\n",
      "Descrição: Move or rename a file from one location to another\n",
      "Args: {'source_path': {'title': 'Source Path', 'description': 'Path of the file to move', 'type': 'string'}, 'destination_path': {'title': 'Destination Path', 'description': 'New path for the moved file', 'type': 'string'}}\n",
      "\n",
      "Name: read_file\n",
      "Descrição: Read file from disk\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'name of file', 'type': 'string'}}\n",
      "\n",
      "Name: write_file\n",
      "Descrição: Write file to disk\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'name of file', 'type': 'string'}, 'text': {'title': 'Text', 'description': 'text to write to file', 'type': 'string'}, 'append': {'title': 'Append', 'description': 'Whether to append to an existing file.', 'default': False, 'type': 'boolean'}}\n",
      "\n",
      "Name: list_directory\n",
      "Descrição: List files and directories in a specified folder\n",
      "Args: {'dir_path': {'title': 'Dir Path', 'description': 'Subdirectory to list.', 'default': '.', 'type': 'string'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir='arquivos'\n",
    ")\n",
    "tools = tool_kit.get_tools()\n",
    "for tool in tools:\n",
    "    print('Name:', tool.name)\n",
    "    print('Descrição:', tool.description)\n",
    "    print('Args:', tool.args) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dando um exemplo de aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir='arquivos',\n",
    "    selected_tools=['write_file', 'read_file', 'file_search','list_directory']\n",
    ")\n",
    "tools = tool_kit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tools_json = [convert_to_openai_function(tool) for tool in tools]\n",
    "tool_run = {tool.name: tool for tool in tools}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um assistente amigável chamado Isaac capaz de gerenciar arquivos'),\n",
    "    ('user', '{input}')\n",
    "])\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentFinish\n",
    "\n",
    "def roteamento(resultado):\n",
    "    if isinstance(resultado, AgentFinish):\n",
    "        return resultado.return_values['output']\n",
    "    else:\n",
    "        return tool_run[resultado.tool].run(resultado.tool_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "\n",
    "chain = prompt | chat.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser() | roteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olá! Eu sou um assistente amigável chamado Isaac e sou capaz de gerenciar arquivos. Posso escrever texto em arquivos, ler o conteúdo de arquivos, pesquisar arquivos com base em padrões de regex e listar arquivos e diretórios em uma pasta específica. Se precisar de ajuda com alguma dessas tarefas, fique à vontade para me pedir! Como posso ajudar você hoje?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'O que você é capz de fazer?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explorando o Universo das IAs com Hugging Face.pdf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Quais arquivos pdf você tem na pasta?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No files found for pattern *.txt in directory .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Quais arquivos txt você tem na pasta?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File written successfully to notas.txt.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Crie um arquivo txt chamado notas com o seguinte conteúdo \"Isso foi feito por uma LLM\"'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Isso foi feito por uma LLM'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Leia o arquivo notas.txt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
