{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principais métodos de chains com LCEL\n",
    "\n",
    "A interface padrão de LCEL inclui os seguintes métodos:\n",
    "\n",
    "- **stream:** transmitir de volta fragmentos da resposta\n",
    "- **invoke:** chamar a cadeia com um input\n",
    "- **batch:** chamar a cadeia com uma lista de inputs\n",
    "\n",
    "Esses também possuem métodos assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência:\n",
    "\n",
    "- **astream:** transmitir de volta fragmentos da resposta de forma assíncrona\n",
    "- **ainvoke:** chamar a cadeia com um input de forma assíncrona\n",
    "- **abatch:** chamar a cadeia com uma lista de inputs de forma assíncrona\n",
    "- **astream_log:** transmitir de volta etapas intermediárias à medida que acontecem, além da resposta final\n",
    "- **astream_events:** transmitir eventos beta à medida que acontecem na cadeia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o assunto: {assunto}\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "O invoke é o método básico para inserir uma input na cadeia e receber uma resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Cachorrinhos são a melhor companhia para alegrar nossos dias com sua lealdade e carinho incondicional.\"', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 20, 'total_tokens': 50}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-feb1cf28-b951-4692-8582-eb8eaab16046-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'assunto': 'cachorrinhos'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele pode ser rodado como uma simples string quando existe apenas uma input no prompt, mas a forma mais recomendada é informando especificamente o nome da input através de um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são companheiros leais que enchem nossas vidas de alegria e amor incondicional.', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 20, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e83cee0e-4558-4198-8270-cd6cd4d52f6c-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('cachorrinhos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream\n",
    "\n",
    "Para recebermos uma saída conforme ela é gerada pelo modelo utilizamos o stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O cachorrinho é o melhor amigo do homem, sempre fiel e carinhoso."
     ]
    }
   ],
   "source": [
    "for chunck in chain.stream({'assunto': 'cachorrinho'}):\n",
    "    print(chunck.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "Para fazermos múltimpas requisições em paralelo utilizamos o batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Cachorrinhos são alegria em quatro patas, sempre prontos para nos alegrar com suas brincadeiras e lealdade incondicional.', response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 20, 'total_tokens': 58}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-74619b29-27be-45b2-a0e2-e6684353dc9a-0'),\n",
       " AIMessage(content='\"Um gatinho é o melhor amigo que você pode ter, sempre pronto para te fazer companhia e te encher de amor e carinho.\"', response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 19, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9538d682-6d94-4c38-ae1c-5dfd880ae4af-0'),\n",
       " AIMessage(content='Os cavalinhos de carrossel sempre trazem alegria e nostalgia para quem se aventura a dar uma volta neles.', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 19, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-81aa003e-c421-48b4-b0a5-14e14daa8c1e-0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinho'}, {'assunto': 'cavalinhos'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Cachorrinhos são alegria em forma de patinhas e pelagem fofa, trazendo amor e companheirismo para nossas vidas.', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 20, 'total_tokens': 57}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f705e146-799f-414c-ba4d-8c1ad84a3bc0-0'),\n",
       " AIMessage(content='O gatinho é a pura definição de fofura e alegria em forma de pelagem.', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 19, 'total_tokens': 44}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dbdf6dd8-87b7-431d-8e25-9a7ffaf1dfc2-0'),\n",
       " AIMessage(content='Os cavalinhos de carrossel sempre trazem alegria e diversão para as crianças.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 19, 'total_tokens': 42}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1a3d671e-9b8b-46c8-8a58-b4b5e73bd9dc-0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinho'}, {'assunto': 'cavalinhos'}], config={'max_concurrency': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ainvoke\n",
    "\n",
    "Todos os métodos possuem assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def processa_chain(input):\n",
    "    resposta = await chain.ainvoke(input)\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são a alegria em quatro patas que iluminam nossas vidas com amor incondicional e fofura infinita.', response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 20, 'total_tokens': 55}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6c3b6ed5-5013-48e4-97d1-b188f8412848-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1 = asyncio.create_task(processa_chain({'assunto': 'gatinho'}))\n",
    "task2 = asyncio.create_task(processa_chain({'assunto': 'cavalinhos'}))\n",
    "task3 = asyncio.create_task(processa_chain({'assunto': 'cachorrinhos'}))\n",
    "\n",
    "await task1\n",
    "await task2\n",
    "await task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Os cavalinhos de carrossel são símbolos de infância e diversão que nos transportam para um mundo mágico de fantasia.', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 19, 'total_tokens': 52}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b45432e2-ae39-4bf4-bc7a-2a89b03393ae-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a diferença de tempo ao utilizar async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2480289936065674\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "a = time()\n",
    "\n",
    "task1 = asyncio.create_task(processa_chain({'assunto': 'gatinho'}))\n",
    "task2 = asyncio.create_task(processa_chain({'assunto': 'cavalinhos'}))\n",
    "task3 = asyncio.create_task(processa_chain({'assunto': 'cachorrinhos'}))\n",
    "\n",
    "await task1\n",
    "await task2\n",
    "await task3\n",
    "\n",
    "b = time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2890777587890625\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "a = time()\n",
    "\n",
    "task1 = chain.invoke({'assunto': 'gatinho'})\n",
    "task2 = chain.invoke({'assunto': 'cavalinhos'})\n",
    "task3 = chain.invoke({'assunto': 'cachorrinhos'})\n",
    "\n",
    "b = time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
