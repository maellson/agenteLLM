{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 1.1: Conexão com o banco de dados e obtenção dos metadados\n",
    "Essa etapa irá se conectar ao banco de dados PostgreSQL e obter os metadados de todas as tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "# Função para conectar ao banco de dados\n",
    "def connect_db():\n",
    "    try:\n",
    "            # Pegar as credenciais do arquivo .env\n",
    "            db_host = os.getenv('DB_HOST')\n",
    "            db_database = os.getenv('DB_DATABASE')\n",
    "            db_user = os.getenv('DB_USER')\n",
    "            db_password = os.getenv('DB_PASSWORD')\n",
    "            db_port = os.getenv('DB_PORT')\n",
    "\n",
    "            # Conectar ao banco de dados PostgreSQL usando as variáveis do .env\n",
    "            conn = psycopg2.connect(\n",
    "                host=db_host,\n",
    "                database=db_database,\n",
    "                user=db_user,\n",
    "                password=db_password,\n",
    "                port=db_port\n",
    "            )\n",
    "            print(\"Conexão com o banco de dados estabelecida com sucesso!\")\n",
    "            return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar ao banco de dados: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Função para obter os metadados de todas as tabelas\n",
    "def get_all_table_metadata(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name;\n",
    "        \"\"\"\n",
    "        metadata_df = pd.read_sql_query(query, conn)\n",
    "        print(\"Metadados obtidos com sucesso!\")\n",
    "        return metadata_df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter metadados: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testar a conexão e obtenção de metadados\n",
    "conn = connect_db()\n",
    "\n",
    "if conn:\n",
    "    metadata_df = get_all_table_metadata(conn)\n",
    "    if metadata_df is not None:\n",
    "        print(metadata_df.head())  # Mostrando uma amostra dos metadados obtidos\n",
    "    else:\n",
    "        print(\"Erro ao carregar metadados.\")\n",
    "else:\n",
    "    print(\"Erro na conexão com o banco de dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USANDO SLQALCHEMY\n",
    "#### Etapa 1.2 : Conexão com o banco de dados e obtenção dos metadados\n",
    "Essa etapa irá se conectar ao banco de dados PostgreSQL e obter os metadados de todas as tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Função para conectar ao banco de dados usando SQLAlchemy\n",
    "def connect_db_sqlalchemy():\n",
    "    try:\n",
    "        # Pegar as credenciais do arquivo .env\n",
    "        db_host = os.getenv('DB_HOST')\n",
    "        db_database = os.getenv('DB_DATABASE')\n",
    "        db_user = os.getenv('DB_USER')\n",
    "        db_password = os.getenv('DB_PASSWORD')\n",
    "        db_port = os.getenv('DB_PORT')\n",
    "\n",
    "        # Criar a URL de conexão no formato aceito pelo SQLAlchemy\n",
    "        db_url = f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_database}'\n",
    "        \n",
    "        # Criar o engine de conexão usando SQLAlchemy\n",
    "        engine = create_engine(db_url)\n",
    "        print(\"Conexão com o banco de dados estabelecida com sucesso via SQLAlchemy!\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar ao banco de dados com SQLAlchemy: {e}\")\n",
    "        return None\n",
    "\n",
    "# Função para obter os metadados de todas as tabelas usando SQLAlchemy\n",
    "def get_all_table_metadata_sqlalchemy(engine):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name;\n",
    "        \"\"\"\n",
    "        metadata_df = pd.read_sql_query(query, engine)\n",
    "        print(\"Metadados obtidos com sucesso via SQLAlchemy!\")\n",
    "        return metadata_df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter metadados via SQLAlchemy: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testar a conexão e obtenção de metadados com SQLAlchemy\n",
    "engine = connect_db_sqlalchemy()\n",
    "\n",
    "if engine:\n",
    "    metadata_df = get_all_table_metadata_sqlalchemy(engine)\n",
    "    if metadata_df is not None:\n",
    "        print(metadata_df.head())  # Mostrando uma amostra dos metadados obtidos\n",
    "    else:\n",
    "        print(\"Erro ao carregar metadados.\")\n",
    "else:\n",
    "    print(\"Erro na conexão com o banco de dados via SQLAlchemy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 2.1: Gerar o contexto a partir dos metadados\n",
    "Essa etapa transforma os metadados em um contexto que o LLM pode usar para entender a estrutura do banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que cria um contexto a partir dos metadados de todas as tabelas\n",
    "def create_context_from_metadata(metadata_df):\n",
    "    try:\n",
    "        context = \"O banco de dados possui as seguintes tabelas e colunas:\\n\"\n",
    "        \n",
    "        # Agrupar metadados por tabela\n",
    "        tables = metadata_df.groupby('table_name')\n",
    "        \n",
    "        # Para cada tabela, listar as colunas e seus tipos\n",
    "        for table_name, table_data in tables:\n",
    "            context += f\"\\nTabela '{table_name}' possui as seguintes colunas:\\n\"\n",
    "            for index, row in table_data.iterrows():\n",
    "                context += f\"- {row['column_name']} ({row['data_type']})\\n\"\n",
    "        \n",
    "        print(\"Contexto gerado com sucesso!\")\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar o contexto: {e}\")\n",
    "        return None\n",
    "\n",
    "# Gerar o contexto se os metadados foram carregados\n",
    "if metadata_df is not None:\n",
    "    contexto_banco = create_context_from_metadata(metadata_df)\n",
    "    print(contexto_banco[:500])  # Mostrar parte do contexto gerado (primeiros 500 caracteres)\n",
    "else:\n",
    "    print(\"Erro: os metadados não estão disponíveis para gerar o contexto.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 2.Geracao de contexto\n",
    "\n",
    "Consulta aprimorada: Estamos agora capturando mais informações sobre as colunas, incluindo:\n",
    "\n",
    "1. table_name: Nome da tabela.\n",
    "2. column_name: Nome da coluna.\n",
    "3. data_type: Tipo de dado da coluna (ex. varchar, integer).\n",
    "4. is_nullable: Informa se a coluna pode ser nula (YES ou NO).\n",
    "5. character_maximum_length: Limite de caracteres (se for do tipo varchar ou outros tipos de texto).\n",
    "6. Organização dos resultados: O resultado é organizado em um dataframe pandas, com as informações sobre as tabelas e colunas do banco de dados.\n",
    "7. Contagem de tabelas: O código também imprime a quantidade de tabelas únicas no banco de dados, utilizando o método nunique() do pandas para contar as tabelas.\n",
    "8. Debug visual: exibe as 10 primeiras linhas dos metadados para que você possa verificar visualmente se os dados foram carregados corretamente.\n",
    "\n",
    "\n",
    "---MELHORIAS ---\n",
    "1. TRATAR ERROS DE CONSULTA\n",
    "2. MELHORAR O PROMPT PARA TRAZER MAIOR ASSERTIVIDADE NAS CONSULTAS\n",
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter os metadados de todas as tabelas usando SQLAlchemy\n",
    "def get_all_table_metadata_sqlalchemy(engine):\n",
    "    try:\n",
    "        # Consulta para buscar nome da tabela, nome da coluna e tipo de dado\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type, is_nullable, character_maximum_length\n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name, ordinal_position;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Executar a consulta e obter o resultado em um dataframe\n",
    "        metadata_df = pd.read_sql_query(query, engine)\n",
    "        print(\"Metadados obtidos com sucesso via SQLAlchemy!\")\n",
    "        \n",
    "        # Mostrar algumas linhas para verificar se está correto\n",
    "        print(metadata_df.head())\n",
    "        \n",
    "        # Exibir uma visão geral do número de tabelas\n",
    "        table_count = metadata_df['table_name'].nunique()\n",
    "        print(f\"O banco de dados contém {table_count} tabelas.\")\n",
    "\n",
    "        return metadata_df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter metadados via SQLAlchemy: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testar a função de obtenção de metadados com SQLAlchemy\n",
    "if engine:\n",
    "    metadata_df = get_all_table_metadata_sqlalchemy(engine)\n",
    "    if metadata_df is not None:\n",
    "        # Visualizar o dataframe com os metadados\n",
    "        print(metadata_df.head(10))  # Mostrar as 10 primeiras linhas\n",
    "    else:\n",
    "        print(\"Erro ao carregar metadados.\")\n",
    "else:\n",
    "    print(\"Erro na conexão com o banco de dados via SQLAlchemy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto_banco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 3.1: Gerar consulta SQL a partir da pergunta em linguagem natural\n",
    "Agora, vamos integrar o LangChain e o OpenAI para transformar a pergunta do usuário em uma query SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Configuração do OpenAI e LangChain\n",
    "def generate_sql_from_question(pergunta, contexto):\n",
    "    try:\n",
    "        prompt_template = \"\"\"\n",
    "        Você é um assistente que entende a estrutura de um banco de dados. Aqui estão os metadados do banco:\n",
    "\n",
    "        {contexto_tabela}\n",
    "\n",
    "        Baseado nesses metadados, escreva uma consulta SQL para responder à seguinte pergunta:\n",
    "\n",
    "        {pergunta}\n",
    "\n",
    "        SQL:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt_template,\n",
    "            input_variables=[\"contexto_tabela\", \"pergunta\"]\n",
    "        )\n",
    "\n",
    "        # Configurar a API key da OpenAI\n",
    "        openai.api_key = \"sua_chave_openai\"  # Substitua com sua chave de API OpenAI\n",
    "        llm = OpenAI(model=\"text-davinci-003\")  # Usando o modelo da OpenAI\n",
    "\n",
    "        # Criar a cadeia de LangChain para gerar a query SQL\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "        # Gerar a query SQL\n",
    "        sql_query = chain.run(contexto_tabela=contexto, pergunta=pergunta)\n",
    "        print(\"Query SQL gerada com sucesso!\")\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar a query SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de pergunta do usuário\n",
    "pergunta_usuario = \"Quantas pessoas a unidade de saúde Maria das Graças atendeu hoje?\"\n",
    "\n",
    "if contexto_banco:\n",
    "    sql_query_gerada = generate_sql_from_question(pergunta_usuario, contexto_banco)\n",
    "    if sql_query_gerada:\n",
    "        print(f\"Query gerada: {sql_query_gerada}\")\n",
    "    else:\n",
    "        print(\"Erro ao gerar a query.\")\n",
    "else:\n",
    "    print(\"Contexto do banco de dados não disponível.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Código para Gerar Consultas SQL a Partir de Perguntas em Linguagem Natural\n",
    "Abaixo está o código para a integração com o LangChain e o OpenAI, usando a chave da API que será carregada do arquivo .env. Este código cria um prompt dinâmico para gerar a consulta SQL com base nos metadados que obtivemos na etapa anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do Código:\n",
    "1. Carregamento da chave OpenAI a partir do .env:\n",
    "2. A chave da API da OpenAI é carregada do arquivo .env usando o método os.getenv(). Isso evita que você coloque a chave diretamente no código, garantindo segurança.\n",
    "3. PromptTemplate para LangChain:\n",
    "4. Criamos um template de prompt para LangChain, que inclui:\n",
    "5. Os metadados do banco (contexto_tabela), que ajudam o modelo a entender a estrutura do banco.\n",
    "6. A pergunta em linguagem natural do usuário (pergunta).\n",
    "7. O prompt é passado para o modelo OpenAI via LangChain, que usa o modelo padrao (que da data de hoje é o 3.5 turbo),  para gerar a consulta SQL com base nos metadados e na pergunta.\n",
    "8. Geração da Consulta SQL:\n",
    "9. O resultado gerado pelo modelo é a consulta SQL, que será exibida na saída.\n",
    "Verificação de Erros:\n",
    "10. O código contém verificações de erros para garantir que a chave da API foi carregada corretamente, o prompt foi gerado adequadamente e a consulta SQL foi retornada com sucesso.\n",
    "\n",
    "\n",
    "------MELHORIAS---------------\n",
    "\n",
    "DETECTOR DE ERROS DE QUERY\n",
    "RELACAO ENTRE AS TABELAS\n",
    "TRATAMENTO DE ASPAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import openai\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar as variáveis do .env, incluindo a chave da API do OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "# Função para carregar a chave da API OpenAI do .env\n",
    "def get_openai_api_key():\n",
    "    try:\n",
    "        openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not openai_api_key:\n",
    "            raise ValueError(\"A chave da API OpenAI não foi encontrada no arquivo .env.\")\n",
    "        print(\"Chave da API OpenAI carregada com sucesso.\")\n",
    "        return openai_api_key\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar a chave da API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Função para gerar uma consulta SQL a partir de uma pergunta usando LangChain e OpenAI\n",
    "def generate_sql_from_question(pergunta, contexto):\n",
    "    try:\n",
    "        # Carregar a chave da API OpenAI do .env\n",
    "        openai_api_key = get_openai_api_key()\n",
    "        if not openai_api_key:\n",
    "            return None\n",
    "\n",
    "        # Configurar a API key para o OpenAI\n",
    "        openai.api_key = openai_api_key\n",
    "\n",
    "        # Definir o template do prompt que será passado para o LLM\n",
    "        prompt_template = \"\"\"\n",
    "        Você é um assistente de banco de dados que entende a estrutura do banco de dados PostgresSQl. Aqui estão os metadados do banco:\n",
    "\n",
    "        {contexto_tabela}\n",
    "\n",
    "        Baseado nesses metadados, escreva uma consulta SQL para responder à seguinte pergunta:\n",
    "\n",
    "        {pergunta}\n",
    "\n",
    "        SQL:\n",
    "        \"\"\"\n",
    "\n",
    "        # Criar o template do LangChain\n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt_template,\n",
    "            input_variables=[\"contexto_tabela\", \"pergunta\"]\n",
    "        )\n",
    "\n",
    "        # Inicializar o modelo OpenAI para LangChain\n",
    "        llm = OpenAI()\n",
    "\n",
    "        # Configurar a cadeia de LangChain para gerar a query SQL\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "        # Gerar a consulta SQL com base na pergunta do usuário e nos metadados\n",
    "        sql_query = chain.run(contexto_tabela=contexto, pergunta=pergunta)\n",
    "        print(\"Consulta SQL gerada com sucesso!\")\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar a consulta SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de pergunta do usuário e contexto dos metadados gerados anteriormente\n",
    "pergunta_usuario = \"quantas pessoal foram atendida em 2018?\"\n",
    "\n",
    "# Gerar uma amostra de contexto baseado nos metadados obtidos (você pode expandir isso conforme necessário)\n",
    "if metadata_df is not None:\n",
    "    contexto_banco = metadata_df.to_string(index=False)\n",
    "\n",
    "    # Gerar a consulta SQL usando a pergunta do usuário e o contexto dos metadados\n",
    "    sql_query_gerada = generate_sql_from_question(pergunta_usuario, contexto_banco)\n",
    "\n",
    "    # Mostrar a consulta SQL gerada\n",
    "    if sql_query_gerada:\n",
    "        print(f\"Consulta SQL gerada:\\n{sql_query_gerada}\")\n",
    "    else:\n",
    "        print(\"Erro ao gerar a consulta SQL.\")\n",
    "else:\n",
    "    print(\"Os metadados do banco de dados não estão disponíveis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 4.1 : Executar a consulta SQL gerada\n",
    "\n",
    "Nesta etapa, vamos executar a consulta SQL gerada e retornar os resultados como um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para executar a query no banco de dados\n",
    "def execute_query(conn, query):\n",
    "    try:\n",
    "        df_result = pd.read_sql_query(query, conn)\n",
    "        print(\"Query executada com sucesso!\")\n",
    "        return df_result\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao executar a query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Se a query foi gerada com sucesso, execute-a no banco de dados\n",
    "if sql_query_gerada:\n",
    "    df_resultado = execute_query(conn, sql_query_gerada)\n",
    "    if df_resultado is not None:\n",
    "        print(df_resultado.head())  # Mostrar uma amostra dos resultados\n",
    "    else:\n",
    "        print(\"Erro ao executar a query.\")\n",
    "else:\n",
    "    print(\"Query não disponível para execução.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Atualização do Código para Executar a Consulta SQL\n",
    "Abaixo está o código para a execução da consulta SQL gerada, utilizando o SQLAlchemy para conectar ao banco e o pandas para manipular os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para executar a consulta SQL gerada no banco de dados\n",
    "def execute_query(engine, query):\n",
    "    try:\n",
    "        # Executar a consulta SQL e retornar o resultado em um dataframe pandas\n",
    "        df_result = pd.read_sql_query(query, engine)\n",
    "        print(\"Consulta SQL executada com sucesso!\")\n",
    "        return df_result\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao executar a consulta SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Verificar se a consulta SQL foi gerada corretamente\n",
    "if sql_query_gerada:\n",
    "    # Executar a consulta SQL gerada no banco de dados\n",
    "    df_resultado = execute_query(engine, sql_query_gerada)\n",
    "\n",
    "    # Exibir os resultados obtidos, se houver algum\n",
    "    if df_resultado is not None:\n",
    "        print(\"Resultado da consulta:\")\n",
    "        print(df_resultado.head())  # Mostra as primeiras linhas do resultado\n",
    "    else:\n",
    "        print(\"Nenhum resultado encontrado ou erro na execução da consulta.\")\n",
    "else:\n",
    "    print(\"Nenhuma consulta SQL foi gerada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 5.1 : Interpretar o resultado e devolver resposta em linguagem natural\n",
    "Aqui o agente interpreta os resultados e retorna a resposta em linguagem natural para o usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para interpretar o resultado da query e devolver resposta em linguagem natural\n",
    "def interpret_result(df_resultado):\n",
    "    try:\n",
    "        if not df_resultado.empty:\n",
    "            total = df_resultado.iloc[0, 0]\n",
    "            return f\"Foram atendidas {total} pessoas na unidade.\"\n",
    "        return \"Nenhum dado encontrado.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao interpretar o resultado: {e}\")\n",
    "        return \"Erro na interpretação dos dados.\"\n",
    "\n",
    "# Se o resultado foi obtido, interpretar e devolver a resposta\n",
    "if df_resultado is not None:\n",
    "    resposta = interpret_result(df_resultado)\n",
    "    print(f\"Resposta em linguagem natural: {resposta}\")\n",
    "else:\n",
    "    print(\"Não há resultados para interpretar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 minha forma de fazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar o prompt de interpretação de resultados\n",
    "def interpret_result_with_template(df_resultado, pergunta_usuario, sql_query_gerada):\n",
    "    try:\n",
    "        # Transformar o dataframe em string para que o modelo possa interpretar\n",
    "        result_str = df_resultado.to_string(index=False)\n",
    "        \n",
    "        # Criar um template de prompt para LangChain interpretar os resultados\n",
    "        prompt_template = \"\"\"\n",
    "        Você é um assistente de banco de dados. O usuário fez a seguinte pergunta:\n",
    "\n",
    "        Pergunta: {pergunta}\n",
    "\n",
    "        Você gerou a seguinte consulta SQL com base nos metadados do banco de dados:\n",
    "\n",
    "        SQL: {sql_query}\n",
    "\n",
    "        A consulta SQL retornou os seguintes dados:\n",
    "\n",
    "        {resultado}\n",
    "\n",
    "        Com base nisso, explique o resultado da consulta de forma clara e amigável e direta para o usuário.\n",
    "        \"\"\"\n",
    "\n",
    "        # Criar o template do LangChain para processar o prompt\n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt_template,\n",
    "            input_variables=[\"pergunta\", \"sql_query\", \"resultado\"]\n",
    "        )\n",
    "\n",
    "        # Inicializar o modelo OpenAI para LangChain\n",
    "        llm = OpenAI()\n",
    "        \n",
    "        # Criar a cadeia LangChain para gerar a interpretação da resposta\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "        # Gerar a resposta interpretada em linguagem natural\n",
    "        resposta_interpretada = chain.run(pergunta=pergunta_usuario, sql_query=sql_query_gerada, resultado=result_str)\n",
    "        return resposta_interpretada\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao interpretar o resultado: {e}\")\n",
    "        return \"Houve um erro ao interpretar os resultados.\"\n",
    "\n",
    "# Exemplo de execução da função de interpretação de resultados\n",
    "if df_resultado is not None and sql_query_gerada:\n",
    "    resposta_interpretada = interpret_result_with_template(df_resultado, pergunta_usuario, sql_query_gerada)\n",
    "    print(f\"Resposta interpretada em linguagem natural: {resposta_interpretada}\")\n",
    "else:\n",
    "    print(\"Não há resultados ou consulta SQL para interpretar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
